---
title: "Hackathon Digital Justice √† Bologne"
authors: ["Dorian Chevalerias"]
tags: ["hackathon", "IA"]
date: "02/12/2024"
---

# Hackathon Digital Justice √† Bologne

Salut, j'ai fait mon premier Hackathon styl√© au d√©but du mois de novembre. Il √©tait organis√© par le Conseil de l'Europe, et 7 √©quipes √©taient invit√©es √† Bologne, tous frais pay√©s, pour tenter de remporter 3 000 ‚Ç¨ de r√©compense ü§ë.

Mon √©quipe de goats :
- [Sabina Askarova](https://sabinaaskerova.github.io/) 
- [Ghali Zaid](https://zaidghali.vercel.app/)
- [Ayoub Sguiar](https://www.linkedin.com/in/ayoub-sguiar-lhamdani-497786252/)


Je vais vous raconter comment on a voulu cr√©er en deux jours un outil qui aurait d√ª prendre des mois de d√©veloppement, comment on s'est lamentablement plant√©, et comment on a, malgre tout, r√©ussi √† remporter la troisi√®me place gr√¢ce √† une petite filouterie qui a fonctionn√© 5 minutes avant la deadline.

<SectionTitle>
## Avant le Hackathon
</SectionTitle>

D'abord, un peu de contexte.
Le sujet du hackathon √©tait de cr√©er un outil qui permette d'aider les professionnels du droit comme les avocats et les juges √† trouver rapidement et facilement des jugements ayant un rapport avec celui sur lequel ils travaillent.

Pour le moment on n'a aucune id√©e de comment fonctionne le domaine ni que le droit est un domaine hyper complexe. Un exemple de cette complexit√© est que les lois de l'union europ√©enne sont appliqu√©es de mani√®re diff√©rente dans les pays car les lois sont interpr√©t√©es √† travers le prisme de leur juridiction.

Mais bon, on est encore na√Øf, pas grave on se dit que dans tous les cas on a besoin de voir et de comprendre √† quoi ressemblent ces fameux jugements.

On tombe sur un site qui r√©pertorie pleins de compte rendus de jugements ainsi que des "pr√©cis" (des r√©sum√©s de d√©cisions) et qui semble plut√¥t moderne (https://codices.coe.int/codices/documents/welcome).

On se dit que pour faire des mod√®les d'IA on a besoin de beaucoup de ces textes, donc on d√©cide de se lancer dans l'extraction des ces derniers.

### Scraping

J'ai utilis√© une technique tr√®s classique de scraping dont tout le monde devrait √™tre au courant tellement elle est utile.

Cette API √©tait tr√®s peu prot√©g√©e, donc je te conseille de passer √† la partie suivante si tu connais d√©j√† car je n'ai eu besoin d'aucun technique originale pour r√©cup√©rer les donn√©es (contrairement √† quand j'ai reverse engineer l'API SNCF pour faire [mon outil](https://track-my-train-times.vercel.app/) de tracking de prix)

L'id√©e c'est de reproduire la requ√™te cr√©√©e par le frontend vers le backend depuis un script et d'automatiser tout √ßa pour r√©cuper tout ce qu'on veut.

Pour cela on ouvre la console dev sur firefox (F12) et on regarde l'onglet network quand on clique sur "plus"

<Picture src="screen1.webp" />

Une requ√™te GET interressante apparait :

Voici l'url :

`https://codices.coe.int/api/precis/tree?page=1&countryCode=ech&size=20&isFinalized=true`

Et les param√®tres de la requ√™te qu'on peut modifier :

`ECH` correspond √† "European Court of Human rights"

`size` indique le nombre de r√©sultats qu'on veut obtenir.

La r√©ponse √† cette requ√™te contient une liste de 20 Titres + Id + autres infos sur les jugements qu'on veut r√©cup√©rer. ü§ë

<Picture src="{9017DAB9-F2ED-4421-8AD6-736D4F6C82C5}.png" />

On change `size=20` pour `size=10000` et on obtient une liste des 600 jsons qui contiennent `id` et `title`. üëç

On isole maintenant la requete qui permet de charger le texte d'un jugement √† partir de son `id`.

On clique sur un article et on examine l'onglet requ√™te.

<Picture src="screen2.webp" />

Une requete GET vers `https://codices.coe.int/api/precis/DAF7533E-BA85-44F9-432E-08DCD0B6A0AC` qui renvoit un magnifique JSON strucur√©.

Il nous reste √† assembler un simple script python pour automatiser les requ√™tes pour r√©cup√©rer le contenu √† partir de chaque `id` et hop, une bdd avec pleins de jugements dans la poche üòé

Bon dans la vraie vie les donn√©es sont souvent un peu plus compliqu√©es √† scraper notamment parce qu'on ne peut pas souvent tout extraire en changeant `size=20` par `size=10000` pour tout r√©cup√©rer d'un coup mais surtout parce que les donn√©es sont souvent prot√©g√©es par de l'authentification. Il faut alors comprendre comment l'authentification est g√©r√©e.

En pratique, cela revient souvent √† ajouter des headers √† notre requ√™te. Je ferai s√ªrement d'autres articles √† ce sujet.

<SectionTitle>
## backend : embeddings + tsne
</SectionTitle>

Bon en vrai r√©cup√©rer les donn√©es de codices ne nous a pas aid√© tant que √ßa puisque les juges et notamment le goat de la data science √† la cour de cassation Amaury Fouret nous avaient concoct√© un floril√®ge de 5 bases de donn√©es compl√®tement h√©t√©rog√®nes avec des fichier Html, pdf, docx et json.

En tout on avait :

- 20 000 textes de jugements (entre 2 et 15 pages par texte)

- Dans plusieurs langues (anglais, fran√ßais, grec, russe)

- Et cr√©√© dans des juridictions diff√©rentes, c'est-√† dire que le contenu peut √™tre tr√®s diff√©rent.

Notre id√©e √©tait de cr√©er des embeddings sur des r√©sum√©s de ces textes en anglais fait par llama 70b avec un prompt bien trouv√©, puis de les stocker de fa√ßon √† pouvoir faire des calculs de similarit√© rapidement.

On voulait ensuite extraire 3 dimensions int√©ressantes de ces embeddings (environ 1000 dimensions) pour repr√©senter nos jugements sur une map interactive en 3D.

<Picture src="{624DB658-8062-4E93-8F38-465AFB9F0356}.png" />

Cela ressemble beaucoup √† une architecture de RAG, (domaine tr√®s √† la mode surtout comme sujet de stage). On a voulu impl√©menter toutes ces √©tapes plus ou moins √† la main ce qui apr√®s coup n'√©tait peut etre pas la meilleure option, les gagnants ont par exemple utilis√© une solution toute faite : https://weaviate.io

Je ne vais pas d√©tailler ce qu'on a fait puisqu'on a pas pus aller au bout de cette solution, mais [Chroma db](https://github.com/chroma-core/chroma) semble etre un bon outil pour cr√©er une vector database. On l'a fait tourner avec [LegalBert](https://huggingface.co/nlpaueb/legal-bert-base-uncased) en tant qu'embedder et on obtient des r√©sultats tr√®s prometteurs sur notre base de fichiers test avec 600 fichiers.

On lui donne une phrase en input, il cr√©√© un embedding et cherche ceux qui sont les plus proches dans l'espace √† 1000 dimensions.

```python
results = collection.query(query_texts=["Tax fraud committed by foreigners"], n_results=2,)
```

L'indexage a pris une vingtaine de minutes pour ces 600 fichiers,

par contre, lorsqu'on le fait tourner sur une bdd plus grosse de 20 000 ou m√™me 5000 fichiers, impossible de terminer la cr√©ation du vecteur store üòñ.

Ce fut notre plus grosse d√©ception de ce hackathon, avec ce vecteur store fonctionnel on aurait pu, j'en suis s√ªr scorer beaucoup plus au tests technique parce que oui, ce filou d'Amaury a voulu tester rigoureusement les performances de nos impl√©mentations de RAG.

Et les tests qu'il avait pr√©par√©s n'√©taient pas de tout repos ü•µ

<SectionTitle>
## Le test technique
</SectionTitle>

Le jury nous a transmis 60 r√©sum√©s en anglais, chacun correspondant √† un texte issu des bases de donn√©es mentionn√©es dans l'√©nonc√©.

- Les r√©sum√© avaient 3 niveaux de d√©tails (quelques phrases √† 3 pages)

- Les r√©sum√©s sont tous en anglais bien que les textes pouvaient √™tre dans d'autres langues

Il nous fallait renvoyer pour chaque r√©sum√© une liste des 100 textes les plus similaires ids+scores de confiance renvoy√©s par notre outil. üò±

Une heure avant la deadline nous n'avons litt√©ralement aucun moyen de passer une quelconque partie de ce test notre recherche de similarit√© gr√¢ce aux embeddings ayant √©chou√©. Mais nous savions qu'√©chouer ce test nous disqualifie de la comp√©tition, il fallait qu'on trouve une solution.

Et c'est l√† que les mots des mentors nous sont revenus : "vous savez, les embeddings c'est r√©cent que √ßa fonctionne, vous devriez essayer des solutions plus anciennes, √ßa marche aussi tr√®s bien."

Et hop, ni une ni deux je vais chercher un TP qu'on a fait avec Gabriel Frey deux mois auparavant sur ElasticSearch √† TPS.

Un notebook compl√®tement rempli qui d√©crit tout le processus d'impl√©mentation d'Elastic Search pour une bdd de fichiers JSON.

Magnifique, gr√¢ce √† cette solution qu'on parvient √† faire fonctionner 5 min avant la deadline et avec quelques filouteries d'un membre de l'√©quipe : Ayoub on passe quelques tests¬† avec des bons score de confiance.

On est sauv√©s, pas de disqualification !

<SectionTitle>
## Frontend : map 3d + prompt
</SectionTitle>

La partie vraiment originale de notre projet, c'est la visualisation de nos donn√©es sur une map 3D. Il nous fallait les choquer.

On voulait repr√©senter des cas sur une map donc on a fait une map en 3D.
Le site est host sur Vercel et dispo [Ici](https://map-my-justice.vercel.app/)

<Picture src="screen3.webp" />

L'impl√©mentation de la visualisation est faite avec three JS (une biblioth√®que pour faire de la 3d avec React, tr√®s puissante)

Les jurys ont √©t√© assez partag√©s sur cette visualisation car ce n'est pas le genre de chose auxquelles on est habitu√© quand on travaille dans ce domaine je les comprenais, j'aurais du encore plus insister sur la vision que j'avais pendant la pr√©sentation pour qu'ils comprennent que cette d√©mo qu'on a fait en deux jours (et 10 prompts) √©tait loin d'√™tre la version finale que j'avais en t√™te.

J'avais pas mal d'id√©es pour am√©liorer cette visualisation sous forme de map pour la rendre plus styl√©e comme par exemple

- Zoomer directement sur le groupe de cas les plus similaires apr√®s le prompt
- Afficher les cas connect√©s avec des liens au survol
- Utiliser de effets de lumi√®re pour mettre en valeur les zones denses

Je n'ai pas parl√© de comment on passe des embeddings (750 dimensions environ) √† une repr√©sentation 3D pour la Map. C'est parce qu'on a pas eu l'occasion d'explorer cet aspect plus que √ßa.
On avait quand meme une id√©e assez claire puisqu'on savait que des algorithmes comme UMAP et t-SNE pouvaient √™tre utilis√©s pour faire de la repr√©sentation de donn√©es √† haute dimension.

Les autres teams avaient des pr√©sentations vraiment impressionnantes pour la plupart et des gens habitu√©s √† parler en public (on √©tait la seule team avec que des gens qui font de l'info). Cependant ont √©tait les seuls √† avoir propos√© quelque chose de plus qu'un simple moteur de recherche am√©lior√©. On avait la partie visualisation ce qui nous a redonn√© espoir.

Finalement ce qui a sembl√© avoir beaucoup compt√© c'est les performances aux tests techniques, car certaines √©quipes qui ont fait une magnifique pr√©sentation et dont l'outil semblait marcher extr√™mement bien n'ont pas fini dans le classement. On a appris plus tard que leur performances √©taient en fait tr√®s mauvaises et que leur d√©mo √©tait faite avec des fausses donn√©es (comme nous au final sauf qu'on a model qui marche au moins un peu).

Au final on repart avec une troisi√®me place ü•â et l'estomac bien rempli de p√¢tes √† la Bolognaise üçù. 

La ville de Bologne est vraiment magnifique

Faites des hackathons c'est sympa

Bisous

<Picture src="Pasted image 20241204040003.png" />
